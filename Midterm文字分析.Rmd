---
title: "Midterm-Part2"
author: "Peter Chiu"
date: "2019/4/19"
output: html_document
---


# 本篇將作韓國瑜與柯文哲兩人臉書粉絲專頁發文的文字分析
```{r warning=FALSE}
library(dplyr)
library(ggplot2)
library(gridExtra)
library(corrplot)
library(wordcloud2)
library(wordcloud)
library(ggpubr)
library(topicmodels)
library(tidytext)
library(jiebaRD)
library(jiebaR)
```

## 清洗內文，只留下中文字後進行斷詞，只取出詞長度為兩字以上的詞
```{r}
cutter <- worker("tag",stop_word ="stopwords.txt",
                 user = "User.txt" ,encoding = "UTF-8",bylines = T)
myFUN<- function(str) {
  str = gsub("[^[:alpha:]]|[A-Za-z0-9]", "", str)
  seg = cutter[str]
  result = seg
}
```

```{r}
load("HanMA.rda")
load("KeMA.rda")
segment_Han = apply(matrix(HanMessageAll$messageByName), MARGIN = 1, myFUN)
segment_Ke = apply(matrix(KeMessageAll$messageByName), MARGIN = 1, myFUN)
```

```{r}
xseg = worker("tag",stop_word ="stopwords.txt",
              user = "User.txt" ,encoding = "UTF-8",bylines = T)
```

## 韓國瑜與柯文哲發文內容的斷詞與詞性標註
```{r}
xtext_Han = NULL
for (i in 1:length(HanMessageAll$messageByName)){
  t0 = HanMessageAll$messageByName[i]
  t1 = xseg <= t0
  xtext_Han = c(xtext_Han,paste0(t1,collapse=" "))
}
```

```{r}
xtext_Ke = NULL
for (i in 1:length(KeMessageAll$messageByName)){
  t0 = KeMessageAll$messageByName[i]
  t1 = xseg <= t0
  xtext_Ke = c(xtext_Ke,paste0(t1,collapse=" "))
}
```

```{r}
text_df_Han = data.frame(doc_id = 1:length(xtext_Han), text = xtext_Han)
text_df_Ke = data.frame(doc_id = 1:length(xtext_Ke), text = xtext_Ke)
```

```{r}
library(stringr)
tok99 = function(t) str_split(t,"[ ]{1,}")
td1 = unnest_tokens(text_df_Han, word, text, token=tok99)
td2 = td1 %>%
  count(doc_id,word,sort=T) %>%
  ungroup() %>%
  bind_tf_idf(word,doc_id, n)

td_tfidf_Han = arrange(td2,desc(tf_idf))
td_tfidf_Han
```

```{r}
tok99 = function(t) str_split(t,"[ ]{1,}")
td1 = unnest_tokens(text_df_Ke, word, text, token=tok99)
td2 = td1 %>%
  count(doc_id,word,sort=T) %>%
  ungroup() %>%
  bind_tf_idf(word,doc_id, n)

td_tfidf_Ke = arrange(td2,desc(tf_idf))
td_tfidf_Ke
```

```{r}
Hanfreq=data.frame(table(segment_Han[[1]]))
Kefreq=data.frame(table(segment_Ke[[1]]))
```

```{r}
top_Han=Hanfreq%>%arrange(desc(Freq))%>%head(150)
top_Ke=Kefreq%>%arrange(desc(Freq))%>%head(150)
```

## 文字雲
```{r}
# wordcloud(top_Han$Var1,random.order = F, ordered.colors = F, colors=rainbow(1000))
# wordcloud(top_Ke$Var1,random.order = F, ordered.colors = F, colors=rainbow(1000))
# wordcloud(top_Han$Var1, max.words=100)
# wordcloud(top_Ke$Var1, max.words=100)
```
### 目前我的R無法讓我畫出文字雲

---------------------------

## 字詞關聯圖
```{r}
top_Han=top_Han%>%head(30)
top_Ke=top_Ke%>%head(30)
topword=merge(top_Han,top_Ke,by="Var1",all = TRUE)
colnames(topword) = c("words","Han","Ke")
rownames(topword) = topword$words
topword= topword[,-1]
topword[is.na(topword)]<-0
```


```{r}
CoMatrix = as.matrix(topword) %*% t(as.matrix(topword))
total_occurrences <- rowSums(CoMatrix)
smallid = which(total_occurrences < median(total_occurrences))
co_occurrence_d = CoMatrix / total_occurrences
co_occurrence_s = co_occurrence_d[-as.vector(smallid),-as.vector(smallid)]
```

```{r}
require(igraph)
graph <- graph.adjacency(round(co_occurrence_s*10),
                         mode="undirected",
                         diag=FALSE)
plot(graph,
     vertex.label=names(data),
     edge.arrow.mode=0,
     vertex.size=1,
     edge.width=E(graph)$weight,
     layout=layout_with_fr)
```


---------------------------
# **LDA**
## 韓國瑜
```{r}
rownames(Hanfreq) = Hanfreq$Var1
Han_dtm=subset(Hanfreq)%>%select(Freq)
dtm_lda <- LDA(t(Han_dtm), k = 4, control = list(seed = 1234))
dtm_topics <- tidy(dtm_lda, matrix = "beta")
top_terms <- dtm_topics %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)
top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  theme(axis.text.y=element_text(colour="black"))
```

## 柯文哲
```{r}
rownames(Kefreq) = Kefreq$Var1
Ke_dtm=subset(Kefreq)%>%select(Freq)
dtm_lda <- LDA(t(Ke_dtm), k = 4, control = list(seed = 1234))
dtm_topics <- tidy(dtm_lda, matrix = "beta")
top_terms <- dtm_topics %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)
top_terms %>%
  mutate(term = reorder(term, beta)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  theme(axis.text.y=element_text(colour="black"))
```

## **重頭戲：情緒詞**
```{r warning=FALSE}
ntuPosEmo=data.table::fread("ntu-positive.txt", header = T,sep="\r",quote = "", stringsAsFactors = F,encoding = "UTF-8")
ntuNegEmo=data.table::fread("ntu-negative.txt", header = T,sep="\r",quote = "", stringsAsFactors = F,encoding = "UTF-8")
Han_pos=Hanfreq%>%merge(x=.,y=ntuPosEmo,by.x="Var1",by.y="word")%>%summarize(Emo="Han_pos",Value=sum(Freq)/347)
Han_neg=Hanfreq%>%merge(x=.,y=ntuNegEmo,by.x="Var1",by.y="word")%>%summarize(Emo="Han_neg",Value=sum(Freq)/347)
Ke_pos=Kefreq%>%merge(x=.,y=ntuPosEmo,by.x="Var1",by.y="word")%>%summarize(Emo="Ke_pos",Value=sum(Freq)/673)
Ke_neg=Kefreq%>%merge(x=.,y=ntuNegEmo,by.x="Var1",by.y="word")%>%summarize(Emo="Ke_neg",Value=sum(Freq)/673)
Emotion=rbind(Han_pos,Han_neg,Ke_pos,Ke_neg)
ggplot(Emotion,aes(x=Emo,y=Value,fill=Emo))+
  geom_bar(stat = "identity")+ggtitle("情緒詞統計(平均每篇文章)")
```




